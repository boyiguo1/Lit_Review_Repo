---
title: "Nonparametric Survival Models"
author: "Boyi Guo"
output: html_document
bibliography:
  - bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview Paper

-   @Lin2013 reviewed curve interpolation in the context of Cox proportional hazard models, with the aims to provide alternatives to models with implicit linearity with regards to model specification and variable selection. The authors used synthetic data to evaluate the variable selection and predictive performance of the state-of-the-art (by 2013) linear and nonlinear Cox proportional hazard models, i.e. COSSO, adaptive COSSO, LASSO, Adaptive LASSO. Despite the computation intensity of nonlinear (nonparametric) models, the authors suggests to compare the linear models and non-linear models to make assertion on which model is more appropriate.

    In the simulation, the authors examined high-dimensional problem where the author took a two-step strategy: screening + models. This strategy is a little bit surprising to me as the models can be directly applied to address the high dimension problem, even poorly. Overall, the article is very well written, and can be used as **a template for review/ evaluation articles**.

# Cox Model

-   @Leng2006 is one among the earliest literature that expands nonparametric Cox models to the high-dimensional setting, where variable selection is of primary interests. The author applied component selection and smoothing operator method (COSSO) in the context of proportional hazard regression. The advantage of COSSO, in comparison to prior works say smoothing spline, is to shrink coefficients to be exactly zero, mirroring between LASSO and ridge regression. A gradient descent algorithm was provided for model fitting. The tuning of the model is achieved by selecting the smoothing parameter with the minimum approximate cross-validation score, a modification of cross-validation criterion. Another advantage of the proposed method is its ability to model effect of two variables as a surface, similar to ANOVA. The simulation considered a synthetic dataset with 8 variables, among which 5 are active (non-zero coefficient). Both correlation structure among predictors, censoring rate and sample size are considered.

-   @Du2010 proposed another additive cox model with the focus on variable selection among parametric covariates, via sparse penalty, and smoothing of non-parametric additive functions, via smoothing penalty. The joint estimation of parametric coefficeints and smoothing function is achieved by an iterative two-step procedure, reciprocal maximization/minimization of likelihood functions conditioning on with assuming the parametric and non-parametric components from previous iteration respectively. Model selection is via a one-step approximation of the SCAD penalty for the parametric part of the model, and minimizing a proposed Kullback--Leibler ratio statistics for nonparametric part. The numerical studies examine the model performance under situations where sample size and censoring rate are the variables of RNG. In discussions, authors gives some directions where some extension of the current framework is possible.

-   @Yang2018 proposed the additive cox model specifically for high-dimensional data. Its primary aim is to screening the the predictors of the model. It expended the partial likelihood function using the Taylor's expansion where The first derivative and second derivative of the partial likelihood can be used as smooth and sparse penalties. The smoothing functions in this framework adapts B-spline, but I think it is possible to generalized to other member of the spline family. Sure screening property is proven.

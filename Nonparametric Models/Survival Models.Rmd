---
title: "Nonparametric Survival Models"
author: "Boyi Guo"
date: "8/10/2021"
output: html_document
bibliography:
  - bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Cox Model
- @Leng2006 is one among the earliest literature that expands nonparametric Cox models to the high-dimensional setting, where variable selection is of primary interests. The author applied component selection and smoothing operator method (COSSO) in the context of proportional hazard regression. The advantage of COSSO, in comparison to prior works say smoothing spline, is to shrink coefficients to be exactly zero, mirroring between LASSO and ridge regression. A gradient descent algorithm was provided for model fitting. The tuning of the model is achieved by selecting the smoothing parameter with the minimum approximate cross-validation score, a modification of cross-validation criterion. Another advantage of the proposed method is its ability to model effect of two variables as a surface, similar to ANOVA. The simulation considered a synthetic dataset with 8 variables, among which 5 are active (non-zero coefficient). Both correlation structure among predictors, censoring rate and sample size are considered.

- @Du2010 proposed another additive cox model with the focus on variable selection among parametric covariates, via sparse penalty, and smoothing of non-parametric additive functions, via smoothing penalty. The joint estimation of parametric coefficeints and smoothing function is achieved by an iterative two-step procedure, reciprocal maximization/minimization of likelihood functions conditioning on with assuming the parametric and non-parametric components from previous iteration respectively. Model selection is via a one-step approximation of the SCAD penalty for the parametric part of the model, and minimizing a proposed Kullbackâ€“Leibler ratio statistics for nonparametric part. The numerical studies examine the model performance under situations where sample size and censoring rate are the variables of RNG. In discussions, authors gives some directions where some extension of the current framework is possible.

- @Yang2018 proposed the additive cox model specifically for high-dimensional data. Its primary aim is to screening the the predictors of the model. It expended the partial likelihood function using the Taylor's expansion where The first derivative and second derivative of the partial likelihood can be used as smooth and sparse penalties. The smoothing functions in this framework adapts B-spline, but I think it is possible to generalized to other member of the spline family. Sure screening property is proven. 

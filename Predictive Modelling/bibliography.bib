@article{Steyerberg2014,
abstract = {Clinical prediction models provide risk estimates for the presence of disease (diagnosis) or an event in the future course of disease (prognosis) for individual patients. Although publications that present and evaluate such models are becoming more frequent, the methodology is often suboptimal. We propose that seven steps should be considered in developing prediction models: (i) consideration of the research question and initial data inspection; (ii) coding of predictors; (iii) model specification; (iv) model estimation; (v) evaluation of model performance; (vi) internal validation; and (vii) model presentation. The validity of a prediction model is ideally assessed in fully independent data, where we propose four key measures to evaluate model performance: calibration-in-the-large, or the model intercept (A); calibration slope (B); discrimination, with a concordance statistic (C); and clinical usefulness, with decision-curve analysis (D). As an application, we develop and validate prediction models for 30-day mortality in patients with an acute myocardial infarction. This illustrates the usefulness of the proposed framework to strengthen the methodological rigour and quality for prediction models in cardiovascular research.. All rights reserved. {\textcopyright} 2014 The Author.},
author = {Steyerberg, Ewout W. and Vergouwe, Yvonne},
doi = {10.1093/eurheartj/ehu207},
file = {:C\:/Users/boyiguo1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steyerberg, Vergouwe - 2014 - Towards better clinical prediction models Seven steps for development and an ABCD for validation.pdf:pdf},
issn = {15229645},
journal = {European Heart Journal},
keywords = {Calibration,Clinical usefulness,Discrimination,Missing values,Non-linearity,Prediction model,Shrinkage},
number = {29},
pages = {1925--1931},
pmid = {24898551},
title = {{Towards better clinical prediction models: Seven steps for development and an ABCD for validation}},
volume = {35},
year = {2014}
}

@article{Steyerberg2010,
abstract = {The performance of prediction models can be assessed using a variety of methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic [ROC] curve), and goodness-of-fit statistics for calibration.Several new measures have recently been proposed that can be seen as refinements of discrimination measures, including variants of the c statistic for survival, reclassification tables, net reclassification improvement (NRI), and integrated discrimination improvement (IDI). Moreover, decision-analytic measures have been proposed, including decision curves to plot the net benefit achieved by making decisions based on model predictions.We aimed to define the role of these relatively novel approaches in the evaluation of the performance of prediction models. For illustration, we present a case study of predicting the presence of residual tumor versus benign tissue in patients with testicular cancer (n = 544 for model development, n = 273 for external validation).We suggest that reporting discrimination and calibration will always be important for a prediction model. Decision-analytic measures should be reported if the predictive model is to be used for clinical decisions. Other measures of performance may be warranted in specific applications, such as reclassification metrics to gain insight into the value of adding a novel predictor to an established model. {\textcopyright} 2009 by Lippincott Williams & Wilkins.},
author = {Steyerberg, Ewout W. and Vickers, Andrew J. and Cook, Nancy R. and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J. and Kattan, Michael W.},
doi = {10.1097/EDE.0b013e3181c30fb2},
file = {:C\:/Users/boyiguo1/Desktop/Reading/nihms438237.pdf:pdf},
issn = {10443983},
journal = {Epidemiology},
number = {1},
pages = {128--138},
pmid = {20010215},
title = {{Assessing the performance of prediction models: A framework for traditional and novel measures}},
volume = {21},
year = {2010}
}


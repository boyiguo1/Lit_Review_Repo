@article{Heil2021,
author = {Heil, Benjamin J and Hoffman, Michael M and Markowetz, Florian and Lee, Su-in and Greene, Casey S and Hicks, Stephanie C},
doi = {10.1038/s41592-021-01256-7},
file = {:Users/boyiguo/Desktop/Heil_et_al-2021-Nature_Methods.pdf:pdf},
issn = {1548-7091},
journal = {Nature Methods},
mendeley-groups = {Casual Reading},
month = {aug},
publisher = {Springer US},
title = {{Reproducibility standards for machine learning in the life sciences}},
url = {http://dx.doi.org/10.1038/s41592-021-01256-7 https://www.nature.com/articles/s41592-021-01256-7},
year = {2021}
}


@incollection{Satagopan2021,
address = {Cham},
author = {Satagopan, Jaya M. and Mazumdar, Madhu},
booktitle = {Leadership in Statistics and Data Science},
doi = {10.1007/978-3-030-60060-0_4},
file = {:Users/boyiguo/Desktop/Mazumdar Book Chapter_LeadershipInStatistics.pdf:pdf},
isbn = {9783030600600},
mendeley-groups = {Casual Reading},
pages = {47--63},
publisher = {Springer International Publishing},
title = {{Team Science in Biostatistical Collaboration: An Opportunity to Practice Leadership, Embrace Diversity, Manage Conflict, and Share Credit}},
url = {http://link.springer.com/10.1007/978-3-030-60060-0_4},
year = {2021}
}


@article{Whalen2021,
author = {Whalen, Sean and Schreiber, Jacob and Noble, William S and Pollard, Katherine S},
doi = {10.1038/s41576-021-00434-9},
file = {:C\:/Users/boyiguo1/Desktop/s41576-021-00434-9.pdf:pdf},
isbn = {0123456789},
issn = {1471-0056},
journal = {Nature Reviews Genetics},
month = {nov},
publisher = {Springer US},
title = {{Navigating the pitfalls of applying machine learning in genomics}},
url = {https://www.nature.com/articles/s41576-021-00434-9},
volume = {0123456789},
year = {2021}
}

@article{Peng2020,
abstract = {Rapid advances in computing technology over the past few decades have spurred two extraordinary phenomena in science: large-scale and high-throughput data collection coupled with the creation and implementation of complex statistical algorithms for data analysis. Together, these two phenomena have brought about tremendous advances in scientific discovery but have also raised two serious concerns, one relatively new and one quite familiar. The complexity of modern data analyses raises questions about the reproducibility of the analyses, meaning the ability of independent analysts to re-create the results claimed by the original authors using the original data and analysis techniques. While seemingly a straightforward concept, reproducibility of analyses is typically thwarted by the lack of availability of the data and computer code that were used in the analyses. A much more general concern is the replicability of scientific findings, which concerns the frequency with which scientific claims are confirmed by completely independent investigations. While the concepts of reproduciblity and replicability are related, it is worth noting that they are focused on quite different goals and address different aspects of scientific progress. In this review, we will discuss the origins of reproducible research, characterize the current status of reproduciblity in public health research, and connect reproduciblity to current concerns about replicability of scientific findings. Finally, we describe a path forward for improving both the reproducibility and replicability of public health research in the future.},
archivePrefix = {arXiv},
arxivId = {2007.12210},
author = {Peng, Roger D. and Hicks, Stephanie C.},
doi = {10.1146/annurev-publhealth-012420-105110},
eprint = {2007.12210},
file = {:Users/boyiguo/Downloads/annurev-publhealth-012420-105110.pdf:pdf},
issn = {15452093},
journal = {Annual Review of Public Health},
keywords = {data analysis,replicability,reproducibility},
month = {jul},
pages = {79--93},
pmid = {33467923},
title = {{Reproducible Research: A Retrospective}},
url = {http://arxiv.org/abs/2007.12210},
volume = {42},
year = {2020}
}

@article{Gelman2021,
abstract = {We review the most important statistical ideas of the past half century, which we categorize as: counterfactual causal inference, bootstrapping and simulation-based inference, overparameterized models and regularization, Bayesian multilevel models, generic computation algorithms, adaptive decision analysis, robust inference, and exploratory data analysis. We discuss key contributions in these subfields, how they relate to modern computing and big data, and how they might be developed and extended in future decades. The goal of this article is to provoke thought and discussion regarding the larger themes of research in statistics and data science.},
archivePrefix = {arXiv},
arxivId = {2012.00174},
author = {Gelman, Andrew and Vehtari, Aki},
doi = {10.1080/01621459.2021.1938081},
eprint = {2012.00174},
file = {:Users/boyiguo/Downloads/What are the Most Important Statistical Ideas of the Past 50 Years.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Data analysis,History of statistics,Statistical computing},
number = {536},
pages = {2087--2097},
publisher = {Taylor & Francis},
title = {{What are the Most Important Statistical Ideas of the Past 50 Years?}},
url = {https://doi.org/10.1080/01621459.2021.1938081},
volume = {116},
year = {2021}
}

